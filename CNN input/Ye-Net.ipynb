{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ye-Net CNN Input TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc, ndimage, signal\n",
    "from sklearn.model_selection  import train_test_split\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import ntpath\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from time import time\n",
    "import time as tm\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 SRM filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## 30 SRM FILTERS\n",
    "srm_weights = np.load('SRM_Kernels.npy')\n",
    "biasSRM=numpy.ones(30)\n",
    "print (srm_weights.shape)\n",
    "################################################## TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def Tanh3(x):\n",
    "    tanh3 = K.tanh(x)*T3\n",
    "    return tanh3\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/guide/tpu\n",
    "#https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb\n",
    "#https://colab.research.google.com/notebooks/tpu.ipynb#scrollTo=_pQCOmISAQBu\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ye-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ye_Net(img_size=256):\n",
    "    #tf.keras.backend.clear_session()\n",
    "    \n",
    "    #Inputs\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    print(inputs.shape)\n",
    "    \n",
    "    #Block 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
    "    \n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 2\n",
    "    \n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 3\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 4\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 5\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 6\n",
    "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    layers = tf.keras.layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    predictions = tf.keras.layers.Dense(2,kernel_initializer='glorot_normal', activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    #Model generation\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    #Optimizer\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
    "    #Compilator\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print (\"Ye-net model 2 generated\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining different functions to work with the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Final_Results_Valid(PATH_trained_models):\n",
    "    global AccValid\n",
    "    global LossValid\n",
    "    AccValid = []\n",
    "    LossValid = [] \n",
    "    B_accuracy = 0 #B --> Best\n",
    "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
    "        if filename != ('train') and filename != ('validation'):\n",
    "            print(filename)\n",
    "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "                 _model = Ye_Net()\n",
    "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
    "            loss,accuracy = _model.evaluate(X_valid, y_valid, verbose=0)\n",
    "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
    "\n",
    "            BandAccValid  = accuracy\n",
    "            BandLossValid = loss\n",
    "            AccValid.append(BandAccValid)    \n",
    "            LossValid.append(BandLossValid)  \n",
    "            \n",
    "            if accuracy > B_accuracy:\n",
    "                B_accuracy = accuracy\n",
    "                B_loss = loss\n",
    "                B_name = filename\n",
    "    \n",
    "    print(\"\\n\\nBest\")\n",
    "    print(B_name)\n",
    "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Results_Train(PATH_trained_models):\n",
    "    global AccTrain\n",
    "    global LossTrain\n",
    "    AccTrain = []\n",
    "    LossTrain = [] \n",
    "    B_accuracy = 0 #B --> Best\n",
    "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
    "        if filename != ('train') and filename != ('validation'):\n",
    "            print(filename)\n",
    "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "                 _model = Ye_Net()\n",
    "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
    "            loss,accuracy = _model.evaluate(X_train, y_train, verbose=0)\n",
    "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
    "\n",
    "            BandAccTrain  = accuracy\n",
    "            BandLossTrain = loss\n",
    "            AccTrain.append(BandAccTrain)    \n",
    "            LossTrain.append(BandLossTrain)  \n",
    "            \n",
    "            if accuracy > B_accuracy:\n",
    "                B_accuracy = accuracy\n",
    "                B_loss = loss\n",
    "                B_name = filename\n",
    "    \n",
    "    print(\"\\n\\nBest\")\n",
    "    print(B_name)\n",
    "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Results_Test(PATH_trained_models):\n",
    "    global AccTest\n",
    "    global LossTest\n",
    "    AccTest = []\n",
    "    LossTest= [] \n",
    "    B_accuracy = 0 #B --> Best\n",
    "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
    "        if filename != ('train') and filename != ('validation'):\n",
    "            print(filename)\n",
    "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "                 _model = Ye_Net()\n",
    "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
    "            loss,accuracy = _model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
    "\n",
    "            BandAccTest  = accuracy\n",
    "            BandLossTest = loss\n",
    "            AccTest.append(BandAccTest)    \n",
    "            LossTest.append(BandLossTest)  \n",
    "            \n",
    "            if accuracy > B_accuracy:\n",
    "                B_accuracy = accuracy\n",
    "                B_loss = loss\n",
    "                B_name = filename\n",
    "    \n",
    "    print(\"\\n\\nBest\")\n",
    "    print(B_name)\n",
    "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, model_name, path_img_base):\n",
    "    if not os.path.exists(path_img_base+\"/\"+model_name):\n",
    "       os.makedirs(path_img_base+\"/\"+model_name)\n",
    "\n",
    "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "        model = Ye_Net()\n",
    "    \n",
    "    lossTEST,accuracyTEST   = model.evaluate(X_test, y_test,verbose=None)\n",
    "    lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train,verbose=None)\n",
    "    lossVALID,accuracyVALID = model.evaluate(X_valid, y_valid,verbose=None)\n",
    "\n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(AccTrain)],axis=0))\n",
    "        plt.plot(np.concatenate([np.array([accuracyVALID]),np.array(AccValid)],axis=0))\n",
    "        plt.plot(np.concatenate([np.array([accuracyTEST]),np.array(AccTest)],axis=0)) #Test\n",
    "        plt.title('Accuracy Vs Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_Ye_Net_'+model_name+'.pdf', format='pdf')     \n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(LossTrain)],axis=0))\n",
    "        plt.plot(np.concatenate([np.array([lossVALID]),np.array(LossValid)],axis=0))\n",
    "        plt.plot(np.concatenate([np.array([lossTEST]),np.array(LossTest)],axis=0)) #Test\n",
    "        plt.title('Loss Vs Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(path_img_base+'/'+model_name+'/Loss_Ye_Net_'+model_name+'.pdf', format='pdf') \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_models(AccTest,AccTrain,AccValid):\n",
    "    numbers=AccTest\n",
    "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
    "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
    "        index, value = numbers_sort[i]\n",
    "        print(\"Test Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    numbers=AccTrain\n",
    "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
    "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
    "        index, value = numbers_sort[i]\n",
    "        print(\"Train Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    numbers=AccValid\n",
    "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
    "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
    "        index, value = numbers_sort[i]\n",
    "        print(\"Validation Accuracy {}, epoch:{}\\n\".format(value, index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTPU(path_model, epochs, model_Name):\n",
    "    global model_name\n",
    "    start_time = tm.time()\n",
    "    model_name = model_Name\n",
    "    path_log_base = path_model+'/'+model_Name\n",
    "    if not os.path.exists(path_log_base):\n",
    "        os.makedirs(path_log_base)\n",
    "\n",
    "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "         model = Ye_Net()\n",
    "\n",
    "    epoch_ = 1\n",
    "    for epoch in range(epochs):\n",
    "        epoch=epoch+1\n",
    "        print(\"epoch \",epoch)\n",
    "        model.fit(X_train,y_train,validation_data=(X_valid,y_valid), batch_size=128*2, epochs=epoch_, verbose=1) \n",
    "        model.save_weights(path_model+'/'+model_name+'/'+str(epoch).zfill(4)+'.hdf5', overwrite=True) \n",
    "\n",
    "    TIME = tm.time() - start_time\n",
    "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BOSSbase 1.01 WOW y PAYLOAD = 0.4bpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the README, there is a link to download the databases we use for the work. There is BOSSbase 1.01, cover images and stego. The steganographic algorithms used in the paper are WOW and S-UNIWARD, with a payload of 0.4bpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different - CNN Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the learning process and avoid issueswith GPU memory limitation, CNN optimization is performed overbatches of images rather than the complete training set. This dataset division means that the class distribution within each batch of images affects the learning process. To demonstrate the effects of stego-cover image quantity for a batch in the learning processand find the best way of feeding the images to the network, three different approaches were tested; \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Usual(providing all the cover images, then all the stego images) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Random(random positions of cover and stego images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-order (alter-nates cover and stego images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Any of the nine \"CNN Input\" can be used to train your model, you can also download the databases in PGM format through a link found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Train image distribution \"Random\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####random train\n",
    "idx=np.arange(len(X))\n",
    "random.shuffle(idx)\n",
    "X=X[idx]\n",
    "Xt=Xt[idx]\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Train image distribution \"Random\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####random train\n",
    "idx1=np.arange(len(X))\n",
    "random.shuffle(idx1)\n",
    "X=X[idx1]\n",
    "Xt=Xt[idx1]\n",
    "\n",
    "####random valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Train image distribution \"Order\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
    "\n",
    "\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "X_valid = CS_X(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [4] Train image distribution \"Usual\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [5] Train image distribution \"Order\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
    "\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [6] Train image distribution \"Order\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "Z = (numpy.vstack((Zc, Zs)))\n",
    "\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "####Random valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [7] Train image distribution \"Random\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
    "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "####Random train\n",
    "idx1=np.arange(len(X))\n",
    "random.shuffle(idx1)\n",
    "X=X[idx1]\n",
    "Xt=Xt[idx1]\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [8] Train image distribution \"Usual\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####random valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [9] Train image distribution \"Usual\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2)\n",
    "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
    "\n",
    "X_train = np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4)\n",
    "X_valid = CS_y(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"./WOW/logs\"\n",
    "path_img_base = \"./Image/WOW/images\"\n",
    "\n",
    "model_Name = \"Ye_Net...\"\n",
    "\n",
    "trainTPU(path_model=path_model, epochs=150, model_Name = \"Ye_Net...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Results_Test(path_model+\"/\"+model_Name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Results_Valid(path_model+\"/\"+model_Name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Results_Train(path_model+\"/\"+model_Name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, model_Name, path_img_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semillero",
   "language": "python",
   "name": "semillero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
