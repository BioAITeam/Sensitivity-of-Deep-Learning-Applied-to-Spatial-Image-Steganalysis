{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xu-Net CNN Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras.layers import Activation\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Lambda, Layer, ReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, SpatialDropout2D, Concatenate\n",
    "tf.keras.layers.Concatenate()\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers.core import Reshape\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import Input, Model\n",
    "from time import time\n",
    "import time as tm\n",
    "from keras.initializers import Constant, RandomNormal, glorot_normal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import  concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 SRM filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## 30 SRM FILTERS\n",
    "srm_weights = np.load('SRM_Kernels.npy')\n",
    "biasSRM=numpy.ones(30)\n",
    "print (srm_weights.shape)\n",
    "################################################## TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def Tanh3(x):\n",
    "    tanh3 = K.tanh(x)*T3\n",
    "    return tanh3\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xu-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xu_Net( img_size=256, compile=True):\n",
    "    \n",
    "    #tf.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    print (\"using\",2,\"classes\")\n",
    "    \n",
    "    #Preprocessing\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
    "\n",
    "\n",
    "    \n",
    "    #Block 1\n",
    "    \n",
    "    #Layer 0\n",
    "    layers = Conv2D(8, (5,5), strides=(1,1),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = Concatenate()([layers, layers, layers])\n",
    "    \n",
    "    #Block 2\n",
    "    \n",
    "    #Layer 1\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = Conv2D(16, (5,5), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)  \n",
    "    layers = AveragePooling2D((5,5), strides= 2, padding='same')(layers)\n",
    "    \n",
    "    #Block 3\n",
    "    \n",
    "    #Layer 2\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = Conv2D(32, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = AveragePooling2D((5,5), strides= 2,padding=\"same\")(layers)\n",
    "    \n",
    "    #Block 4\n",
    "    #Layer 3\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = Conv2D(64, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
    "    #Block 5\n",
    "    #Layer 4\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = Conv2D(128, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = Concatenate()([layers, layers, layers])\n",
    "    layers = GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    \n",
    "    #Block 6\n",
    "    #Layer 5, FC, Softmax\n",
    "  \n",
    "    #FC\n",
    "    layers = Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "   \n",
    "    #Softmax\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    model =tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    #Compile\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)\n",
    "    \n",
    "    if compile:\n",
    "        model.compile(optimizer= optimizer,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        print (\"Xunet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining different functions to work with the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size, epochs, initial_epoch = 0, model_name=\"\"):\n",
    "    start_time = tm.time()\n",
    "    log_dir=\"/content/drive/My Drive/Colab Notebooks/Steganalysis/logs/\"+model_name+\"_\"+\"{}\".format(time())\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir)\n",
    "    filepath = log_dir+\"/saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=False, mode='max')\n",
    "    model.reset_states()\n",
    "    history=model.fit(X_train, y_train, epochs=epochs, \n",
    "                        callbacks=[tensorboard,checkpoint], \n",
    "                        batch_size=batch_size,validation_data=(X_valid, y_valid),initial_epoch=initial_epoch)\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    results_dir=\"/content/drive/My Drive/Colab Notebooks/Steganalysis/Results/\"+model_name+\"/\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "      \n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,1)\n",
    "        #Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Accuracy Vs Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Accuracy_Xu_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Loss Vs Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Loss_Xu_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['lr'])\n",
    "        plt.ylabel('Lr')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid('on')\n",
    "        plt.show()\n",
    "        '''\n",
    "    TIME = tm.time() - start_time\n",
    "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BOSSbase 1.01 WOW y PAYLOAD = 0.4bpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the README, there is a link to download the databases we use for the work. There is BOSSbase 1.01, cover images and stego. The steganographic algorithms used in the paper are WOW and S-UNIWARD, with a payload of 0.4bpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different - CNN Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the learning process and avoid issueswith GPU memory limitation, CNN optimization is performed overbatches of images rather than the complete training set. This dataset division means that the class distribution within each batch of images affects the learning process. To demonstrate the effects of stego-cover image quantity for a batch in the learning processand find the best way of feeding the images to the network, three different approaches were tested; \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Usual(providing all the cover images, then all the stego images) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Random(random positions of cover and stego images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-order (alter-nates cover and stego images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Any of the nine \"CNN Input\" can be used to train your model, you can also download the databases in PGM format through a link found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Train image distribution \"Random\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "#S-UNIWARD 0.4bpp\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####aleatorio train\n",
    "idx=np.arange(len(X))\n",
    "random.shuffle(idx)\n",
    "X=X[idx]\n",
    "Xt=Xt[idx]\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Train image distribution \"Random\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "#S-UNIWARD 0.4bpp\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####aleatorio train\n",
    "idx1=np.arange(len(X))\n",
    "random.shuffle(idx1)\n",
    "X=X[idx1]\n",
    "Xt=Xt[idx1]\n",
    "\n",
    "####aleatorio valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Train image distribution \"Order\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#LECTURA DE LAS IMAGENES POR CARPETA\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "#PONER EN ORDEN COVER_STEGO LAS IMÁGENES\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "#PONER EN ORDEN LAS CORRESPONDIENTES ETIQUETAS\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "#S-UNIWARD 0.4bpp\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
    "\n",
    "\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "X_valid = CS_X(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [4] Train image distribution \"Usual\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "#S-UNIWARD 0.4bpp\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [5] Train image distribution \"Order\", and Validation image distribution \"Usual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#LECTURA DE LAS IMAGENES POR CARPETA\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "#PONER EN ORDEN COVER_STEGO LAS IMÁGENES\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "#PONER EN ORDEN LAS CORRESPONDIENTES ETIQUETAS\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
    "\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [6] Train image distribution \"Order\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#LECTURA DE LAS IMAGENES POR CARPETA\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "#PONER EN ORDEN COVER_STEGO LAS IMÁGENES\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "#PONER EN ORDEN LAS CORRESPONDIENTES ETIQUETAS\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2))\n",
    "X_train = CS_X(np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4))\n",
    "\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "Z = (numpy.vstack((Zc, Zs)))\n",
    "\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "####aleatorio valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [7] Train image distribution \"Ramdom\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#LECTURA DE LAS IMAGENES POR CARPETA\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "#PONER EN ORDEN COVER_STEGO LAS IMÁGENES\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "#PONER EN ORDEN LAS CORRESPONDIENTES ETIQUETAS\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "#Test Images\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_valid = np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2)\n",
    "X_valid = np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4)\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "####aleatorio train\n",
    "idx1=np.arange(len(X))\n",
    "random.shuffle(idx1)\n",
    "X=X[idx1]\n",
    "Xt=Xt[idx1]\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [8] Train image distribution \"Usual\", and Validation image distribution \"Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "#S-UNIWARD 0.4bpp\n",
    "\n",
    "#Train Images\n",
    "Xc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Yc = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Ys = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "\n",
    "X = (numpy.vstack((Xc, Xs)))\n",
    "Y = (numpy.vstack((Yc, Ys)))\n",
    "\n",
    "\n",
    "Xt = (numpy.hstack(([0]*len(Xc), [1]*len(Xs))))\n",
    "Yt = (numpy.hstack(([0]*len(Yc), [1]*len(Ys))))\n",
    "\n",
    "\n",
    "Xt = np_utils.to_categorical(Xt, 2)\n",
    "Yt = np_utils.to_categorical(Yt, 2)\n",
    "\n",
    "\n",
    "####aleatorio valid\n",
    "idx2=np.arange(len(Y))\n",
    "random.shuffle(idx2)\n",
    "Y=Y[idx2]\n",
    "Yt=Yt[idx2]\n",
    "\n",
    "\n",
    "X=np.rollaxis(X,1,4)  #channel axis shifted to last axis\n",
    "Y=np.rollaxis(Y,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "\n",
    "X_train=X\n",
    "y_train=Xt\n",
    "X_valid=Y\n",
    "y_valid=Yt\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## [9] Train image distribution \"Usual\", and Validation image distribution \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#LECTURA DE LAS IMAGENES POR CARPETA\n",
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    data=[]\n",
    "    for f in files:\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                data.append( [ patches[i,j] ] )\n",
    "    data=numpy.array(data)\n",
    "    return data\n",
    "#PONER EN ORDEN COVER_STEGO LAS IMÁGENES\n",
    "def CS_X(X):\n",
    "    X2 = X.copy()\n",
    "    j=0\n",
    "    k=int(len(X)/2)\n",
    "    for i in range(int(len(X)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            X2[i,:,:,0] = X[j,:,:,0]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            X2[i,:,:,0] = X[k,:,:,0]\n",
    "            k=k+1\n",
    "    return X2\n",
    "#PONER EN ORDEN LAS CORRESPONDIENTES ETIQUETAS\n",
    "def CS_y(y):\n",
    "    y2 = y.copy()\n",
    "    j=0\n",
    "    k=int(len(y)/2)\n",
    "    for i in range(int(len(y)-1)):\n",
    "        if i%2 == 0: #par \n",
    "            y2[i,:] = y[j,:]\n",
    "            j=j+1\n",
    "        if i%2 == 1: #impar \n",
    "            y2[i,:] = y[k,:]\n",
    "            k=k+1\n",
    "    return y2\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "#Train Images\n",
    "Xc0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/cover/*.pgm')\n",
    "Xs0 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/train/stego/*.pgm')\n",
    "#Validation Images\n",
    "Xc1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/cover/*.pgm')\n",
    "Xs1 = load_images('/DATABASES/BOSSbase-1.01/WOW/0.4bpp/valid/stego/*.pgm')\n",
    "\n",
    "##################################################################################################################\n",
    "\n",
    "y_train = np_utils.to_categorical((numpy.hstack(([0]*len(Xc0), [1]*len(Xs0)))), 2)\n",
    "y_valid = CS_y(np_utils.to_categorical((numpy.hstack(([0]*len(Xc1), [1]*len(Xs1)))), 2))\n",
    "\n",
    "X_train = np.rollaxis((numpy.vstack((Xc0, Xs0))),1,4)\n",
    "X_valid = CS_y(np.rollaxis((numpy.vstack((Xc1, Xs1))),1,4))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN name and algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name=\"04WOW1\"\n",
    "m_name=\"XU_Net\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Xu_Net() \n",
    "name=\"Model_\"+m_name+\"_\"+base_name\n",
    "_, history  = train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=64, epochs=100, model_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semillero",
   "language": "python",
   "name": "semillero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
