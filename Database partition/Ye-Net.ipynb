{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ye-Net with different Database Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from keras.layers import Activation\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Lambda, Layer, ReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, SpatialDropout2D, Concatenate\n",
    "tf.keras.layers.Concatenate()\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers.core import Reshape\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import Input, Model\n",
    "from time import time\n",
    "import time as tm\n",
    "from keras.initializers import Constant, RandomNormal, glorot_normal\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import  concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 SRM filters for preprocessing and the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## 30 SRM FILTERS\n",
    "srm_weights = np.load('SRM_Kernels.npy') \n",
    "biasSRM=numpy.ones(30)\n",
    "print (srm_weights.shape)\n",
    "################################################## TLU ACTIVATION FUNCTION\n",
    "T3 = 3;\n",
    "def Tanh3(x):\n",
    "    tanh3 = K.tanh(x)*T3\n",
    "    return tanh3\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ye-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ye_Net(img_size=256):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    #Inputs\n",
    "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
    "    print(inputs.shape)\n",
    "    \n",
    "    #Block 1\n",
    "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
    "    #layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    #layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 2\n",
    "    \n",
    "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    \n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 3\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 4\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers) \n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 5\n",
    "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
    "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
    "    print(layers.shape)\n",
    "    \n",
    "    #Block 6\n",
    "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
    "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
    "    layers = tf.keras.layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    #layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    #layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
    "    predictions = tf.keras.layers.Dense(2,kernel_initializer='glorot_normal', activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    #Model generation\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    #Optimizer\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
    "    #Compilator\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print (\"Ye-net model 2 generated\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining different functions to work with the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size, epochs, initial_epoch = 0, model_name=\"\"):\n",
    "    start_time = tm.time()\n",
    "    log_dir=\"/content/drive/My Drive/Colab Notebooks/Steganalysis/logs/\"+model_name+\"_\"+\"{}\".format(time())\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir)\n",
    "    filepath = log_dir+\"/saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=False, mode='max')\n",
    "    model.reset_states()\n",
    "    history=model.fit(X_train, y_train, epochs=epochs, \n",
    "                        callbacks=[tensorboard,checkpoint], \n",
    "                        batch_size=batch_size,validation_data=(X_valid, y_valid),initial_epoch=initial_epoch)\n",
    "    \n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    results_dir=\"/content/drive/My Drive/Colab Notebooks/Steganalysis/Results/\"+model_name+\"/\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "      \n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,1)\n",
    "        #Plot training & validation accuracy values\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Accuracy Vs Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Loss Vs Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['lr'])\n",
    "        plt.ylabel('Lr')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid('on')\n",
    "        plt.show()\n",
    "        '''\n",
    "    TIME = tm.time() - start_time\n",
    "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Results_Test(model,PATH_trained_models):\n",
    "    B_accuracy = 0 #B --> Best\n",
    "    for filename in os.listdir(PATH_trained_models):\n",
    "        if filename != ('train') and filename != ('validation'):\n",
    "            print(filename)\n",
    "            model.load_weights(PATH_trained_models+'/'+filename)\n",
    "            loss,accuracy = model.evaluate(X_test, y_test,verbose=0)\n",
    "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n') \n",
    "            if accuracy > B_accuracy:\n",
    "                B_accuracy = accuracy\n",
    "                B_loss = loss\n",
    "                B_name = filename\n",
    "    print(\"\\n\\nBest\")\n",
    "    print(B_name)\n",
    "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def plot_train_valid(model,PATH_trained_models,model_name):\n",
    "    acc_train=[]\n",
    "    acc_valid=[]\n",
    "    loss_train=[]\n",
    "    loss_valid=[]\n",
    "    for filename in tqdm(os.listdir(PATH_trained_models)):\n",
    "        if filename != ('train') and filename != ('validation'):\n",
    "            print(filename)\n",
    "            model.load_weights(PATH_trained_models+'/'+filename)\n",
    "            loss,accuracy = model.evaluate(X_train, y_train,verbose=0)\n",
    "            acc_train.append(accuracy)\n",
    "            loss_train.append(loss)\n",
    "            loss,accuracy = model.evaluate(X_valid, y_valid,verbose=0)\n",
    "            acc_valid.append(accuracy)\n",
    "            loss_valid.append(loss)\n",
    "\n",
    "    results_dir=\"/content/drive/My Drive/Colab Notebooks/Steganalysis/Results/\"+model_name+\"/\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    with plt.style.context('seaborn-white'):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,1)\n",
    "        #Plot training & validation accuracy values\n",
    "        plt.plot(acc_train)\n",
    "        plt.plot(acc_valid)\n",
    "        plt.title('Accuracy Vs Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Accuracy_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(loss_train)\n",
    "        plt.plot(loss_valid)\n",
    "        plt.title('Loss Vs Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "        plt.grid('on')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.eps', format='eps')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.svg', format='svg')\n",
    "        plt.savefig(results_dir+'Loss_Ye_Net_'+model_name+'.pdf', format='pdf')\n",
    "        plt.show()\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        #plt.subplot(1,2,2)\n",
    "        #Plot training & validation loss values\n",
    "        plt.plot(history.history['lr'])\n",
    "        plt.ylabel('Lr')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.grid('on')\n",
    "        plt.show()\n",
    "        '''\n",
    "    results={'acc_train':acc_train,'acc_valid':acc_valid,'loss_train':loss_train,'loss_valid':loss_valid}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with BOSSbase 1.01 WOW y PAYLOAD = 0.4bpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the README, there is a link to download the databases we use for the work. There is BOSSbase 1.01, cover images and stego. The steganographic algorithms used in the paper are WOW and S-UNIWARD, with a payload of 0.4bpp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose any of the Database partition and train model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Any of the nine \"CNN Input\" can be used to train your model, you can also download the databases in PGM format through a link found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training image pairs(4000), Validation image pairs(1000), and Test image pairs(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training image pairs(2500), Validation image pairs(2500), and Test image pairs(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:2500],X_[10000:12500]],axis=0)\n",
    "X_valid = np.concatenate([X_[2500:5000],X_[12500:15000]],axis=0)\n",
    "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:2500],Xt_[10000:12500]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[2500:5000],Xt_[12500:15000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training image pairs(4000), Validation image pairs(3000), and Test image pairs(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
    "X_valid = np.concatenate([X_[4000:7000],X_[14000:17000]],axis=0)\n",
    "X_test  = np.concatenate([X_[7000:10000],X_[17000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[4000:7000],Xt_[14000:17000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[7000:10000],Xt_[17000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training image pairs(8000), Validation image pairs(1000), and Test image pairs(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=256\n",
    "def load_images(path_pattern):\n",
    "    files=glob.glob(path_pattern)\n",
    "    X=[]\n",
    "    for f in sorted(files):\n",
    "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        patches = view_as_blocks(I, (n, n))\n",
    "        for i in range(patches.shape[0]):\n",
    "            for j in range(patches.shape[1]):\n",
    "                X.append( [ patches[i,j] ] )\n",
    "    X=numpy.array(X)\n",
    "    return X\n",
    "\n",
    "pathc = './DATABASES/BOSSbase-1.01'\n",
    "paths = './DATABASES/BOSSbase-1.01/S-UNIWARD/0.4bpp'\n",
    "\n",
    "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
    "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
    "X_  = (numpy.vstack((Xc_, Xs_)))\n",
    "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
    "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
    "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
    "\n",
    "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
    "#Cover hasta las 10000 ##Train hasta las 4000 ##Valid hasta de las 4000 a las 5000 ##Test de las 5000 a las 10000\n",
    "X_train = np.concatenate([X_[0:8000],X_[10000:18000]],axis=0)\n",
    "X_valid = np.concatenate([X_[8000:9000],X_[18000:19000]],axis=0)\n",
    "X_test  = np.concatenate([X_[9000:10000],X_[19000:20000]],axis=0)\n",
    "y_train = np.concatenate([Xt_[0:8000],Xt_[10000:18000]],axis=0)\n",
    "y_valid = np.concatenate([Xt_[8000:9000],Xt_[18000:19000]],axis=0)\n",
    "y_test  = np.concatenate([Xt_[9000:10000],Xt_[19000:20000]],axis=0)\n",
    "#Controled randomized data for training\n",
    "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64) \n",
    "X_train = np.concatenate([X_dat0,X_dat1],axis=0) \n",
    "y_train = np.concatenate([y_dat0,y_dat1],axis=0) \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN name and algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name=\"04WOW1\"\n",
    "m_name=\"YE_Net\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Ye_Net() \n",
    "name=\"Model_\"+m_name+\"_\"+base_name\n",
    "_, history  = train(model, X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=64, epochs=100, model_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Ye_Net() \n",
    "PATH_trained_models = \" \"\n",
    "Final_Results_Test(model,PATH_trained_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and testing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Ye_Net()  \n",
    "PATH_trained_models = \"\"\n",
    "name=\"Model_\"+m_name+\"_\"+base_name\n",
    "res=plot_train_valid(model,PATH_trained_models,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semillero",
   "language": "python",
   "name": "semillero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
